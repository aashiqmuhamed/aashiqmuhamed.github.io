@inproceedings{muhamed2021symbolic,
  title={{Symbolic Music Generation with Transformer-GANs}},
  author={\textbf{A. Muhamed} and Li, Liang and Shi, Xingjian and Yaddanapudi, Suri and Chi, Wayne and Jackson, Dylan and Suresh, Rahul and Lipton, Zachary C and Smola, Alexander J},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={1},
  pages={408--417},
  year={2021},
  keywords={conference},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/16117}
}
@article{taogated,
  title={{Gated Transformer for Decoding Human Brain EEG Signals}},
  author={Tao, Yunzhe and Sun, Tao and \textbf{A. Muhamed} and Genc, Sahika and Jackson, Dylan and Arsanjani, Ali and Yaddanapudi, Suri and Li, Liang and Kumar, Prachi},
  journal={43rd Annual International Conference of the IEEE Engineering in Medicine   Biology Society (EMBC)},
  year={2021},
  volume={},
  number={},
  pages={},
  keywords={conference},
  url={https://tinyurl.com/eb9c6y3b}
}
% WWW submission
@inproceedings{muhamedwww,
  title={{DCAF-BERT: A Distilled Cachable Adaptable Factorized Model For Improved Ads CTR Prediction}},
  author={\textbf{A. Muhamed} and Singh, Jaspreet and Zheng, Shuai and Keivanloo, Iman and Perera, Sujan and Mracek, James  and Xu, Yi and Cui, Qingjun and Rajagopalan, Santosh and Zeng, Belinda and Chilimbi, Trishul},
  booktitle={WWW '22: Proceedings of the Web Conference},
  note={...},
  year={2022},
  keywords={conference},
}

% KDD submission
@inproceedings{nigam2019semantic,
  title={{Web-scale Semantic Product Search With Large Language Models}},
  author={\textbf{A. Muhamed*} and Srinivasan*, Sriram and Hui Teo, Choon and Cui, Qingjun and Zeng, Belinda and Chilimbi, Trishul and Vishwanathan, SVN },
  booktitle={Advances in Knowledge Discovery and Data Mining: 27th Pacific-Asia Conference PAKDD, Osaka, Japan},
  pages={},
  year={2023},
  keywords={conference},
}



% ACL submission
@inproceedings{jianyi2023acl,
  title={{ReAugKD: Retrieval-Augmented Knowledge Distillation for Pre-trained Language Models}},
  author={Zhang, Jianyi and \textbf{A. Muhamed} and Anantharaman, Aditya, and Wang, Guoyin and Chen, Changyou and Zhong, Kai and Cui, Qingjun and Xu, Yi and Zeng, Belinda and Chilimbi, Trishul},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics ACL},
  pages={},
  year={2023},
  keywords={conference},
}



% ACL submission
% @inproceedings{novotny2018semi,
%   title={Adversarial Text to Continuous Image Generation \textit{(under review)}},
%   author={Haydarov, Kilichbek and \textbf{A. Muhamed} and Lazarevic, Jovana and Skorokhodov, Ivan and Elhoseiny, Mohamed},
%   booktitle={The Eleventh International Conference on Learning Representations ICLR},
%   pages={},
%   year={2023},
%   keywords={conference},
% }

% Workshops
@inproceedings{muhamedtransformer,
  title={{Transformer-GAN: Symbolic music generation using a learned loss}},
  author={\textbf{A. Muhamed} and Li, Liang and Shi, Xingjian and Yaddanapudi, Suri and Chi, Wayne and Jackson, Dylan and Suresh, Rahul and Lipton, Zachary and Smola, Alexander J},
  booktitle={4th NeurIPS Workshop on Machine Learning for Creativity and Design},
  year={2020},
  url={https://tinyurl.com/z5h9yfyt},
  keywords={workshop},
}
@inproceedings{muhamedtransformereval,
  title={{Symbolic Music Generation with Transformer-GANs}},
  author={\textbf{A. Muhamed} and Li, Liang and Shi, Xingjian and Suresh, Rahul and Smola, Alexander J},
  booktitle={1st ISMIR Workshop on NLP for Music and Audio (NLP4MusA) \textbf{(Oral spotlight)}},
  year={2020},
  url={https://tinyurl.com/v7zbrj6m},
  keywords={workshop},
}
@inproceedings{muhamedctrbert,
  title={{CTR-BERT: Cost-effective knowledge distillation for billion-parameter teacher models}},
  author={\textbf{A. Muhamed} and Keivanloo, Iman and Perera, Sujan and Mracek, James and Xu, Yi and Cui, Qingjun and Rajagopalan, Santosh and Zeng, Belinda and Chilimbi, Trishul},
  booktitle={NeurIPS Workshop on  Efficient Natural Language
  and Speech Processing (ENLSP) \textbf{(Oral Spotlight)}},
  year={2021},
  url={https://tinyurl.com/4w5r4jpn},
  keywords={workshop},
}

@inproceedings{muhamed2023icml,
  title={{Reverse Distillation: Training Billion Parameter Models For CTR Prediction}},
  author={Anantharam*, Aditya and \textbf{A. Muhamed*} and Pugaliya, Hemant and Ge, Zhen and Wang, Chong and Perera, Sujan and Cui, Qingun and Zeng, Belinda and Chilimbi, Trishul},
  booktitle={ICML Workshop on Efficient Systems for Foundation Models (ES-FoMo)},
  pages={},
  year={2023},
  keywords={workshop},
}

% Patents
@misc{muhamed20203d,
  title={{3D convolutional neural networks for television advertisement detection. US Patent 10,706,286}},
  author={\textbf{A. Muhamed} and Ghose, Susmita and Chow, Dawnis},
  year={2020},
  month=jul # "~7",
  publisher={Google Patents},
  note={US Patent 10,706,286},
  keywords={patent}
}
@misc{muhamed2020text,
  title={{Text independent speaker-verification on a media operating system using deep learning on raw waveforms. US Patent 10,699,715}},
  author={\textbf{A. Muhamed} and Ghose, Susmita},
  year={2020},
  month=jun # "~30",
  publisher={Google Patents},
  note={US Patent 10,699,715},
  keywords={patent}
}


% Deepcomposer blog (education)
@misc{blog,
  title = {{Using Transformers to create music in AWS DeepComposer Music studio}},
  howpublished = {\url{https://tinyurl.com/cz92ac7k}},
  note = {Accessed: 2021-10-16}
}
@misc{ar-cnn,
  title = {{Generating compositions in the style of Bach using the AR-CNN algorithm in AWS DeepComposer}},
  howpublished = {\url{https://tinyurl.com/4k2w4dac}},
  note = {Accessed: 2021-10-16}
}
% Code
@misc{codebase1,
  title = {{AWS Deepcomposer code repository: AR-CNN, GANs, Transformers}},
  howpublished = {\url{https://github.com/aws-samples/aws-deepcomposer-samples}},
  note = {Accessed: 2021-10-16}
}
@misc{codebase2,
  title = {{Transformer-GAN code repository}},
  howpublished = {\url{https://github.com/amazon-research/transformer-gan}},
  note = {Accessed: 2021-10-16}
}
% Lead scientist at
@misc{awsdeepcomposer,
  title = {{AWS DeepComposer}},
  howpublished = {\url{https://aws.amazon.com/deepcomposer/}},
  note = {Accessed: 2021-10-16}
}
@misc{awsdeeplens,
  title = {{AWS Deeplens}},
  howpublished = {\url{https://aws.amazon.com/deeplens/}},
  note = {Accessed: 2021-10-16}
}
% press coverage
@misc{article1,
  title = {{AWS announces DeepComposer, a machine-learning keyboard for developers}},
  howpublished = {\url{https://techcrunch.com/2019/12/02/aws-announces-deepcomposer-a-machine-learning-keyboard-for-developers/}},
  note = {Accessed: 2021-10-16},
  keywords={press}
}
@misc{article2,
  title = {{Amazon launches AI-powered keyboard, AWS DeepComposer}},
  howpublished = {\url{https://www.factmag.com/2019/12/03/amazon-aws-deepcomposer-ai-keyboard/}},
  note = {Accessed: 2021-10-16},
  keywords={press}
}
@misc{article3,
  title = {{Amazon Announces ‘DeepComposer,’ the World’s First Machine-Learning USB Musical Keyboard for Developers of All Skill Levels}},
  howpublished = {\url{https://gritdaily.com/aws-announces-first-machine-learning-keyboard-deepcomposer/}},
  note = {Accessed: 2021-10-16},
  keywords={press}
}
@misc{article4,
  title = {{Amazon created a musical keyboard to help developers learn about AI}},
  howpublished = {\url{https://www.engadget.com/2019-12-02-amazon-aws-deepcomposer.html}},
  note = {Accessed: 2021-10-16},
  keywords={press}
}
@misc{article5,
  title = {{AWS DeepComposer - Jonathan Coulton Performance at AWS re:Invent 2019}},
  howpublished = {\url{https://www.youtube.com/watch?v=2vdg_45HsTo}},
  note = {Accessed: 2021-10-16},
  keywords={press}
}

% Other
@inproceedings{
anonymous2022hypercgan,
title={{Hyper{CGAN}: Text-to-Image Synthesis with HyperNet-Modulated Conditional Generative Adversarial Networks }},
author={Haydarov, Kilichbek and \textbf{A. Muhamed} and Lazarevic, Jovana and Skorokhodov, Ivan and Elhoseiny, Mohamed},
year={2022},
url={https://openreview.net/forum?id=z-5BjnU3-OQ},
note={...},
keywords={other},
}
@inproceedings{muhamedcvc,
  title={{Designing event representations for symbolic music}},
  author={\textbf{A. Muhamed} and Li, Liang and Shi, Xingjian},
  booktitle={Amazon Computer Vision Conference (CVC)},
  year={2020},
  keywords={other},
}
% ICLR submission
@inproceedings{novotny2018semi,
  title={Adversarial Text to Continuous Image Generation},
  author={Haydarov, Kilichbek and \textbf{A. Muhamed} and Lazarevic, Jovana and Skorokhodov, Ivan and Shen, Xiaoqian and Galappaththige, Chamuditha and Elhoseiny, Mohamed},
  booktitle={},
  pages={},
  year={2023},
  url={https://openreview.net/forum?id=9X3UZJSGIg9},
  keywords={other},
}
@inproceedings{huan2023training,
  author = {\textbf{Muhamed, Aashiq} and Bock, Christian and Solanki, Rahul and Park, Youngsuk and Wang, Yida and Huan, Jun},
  title = {{Tutorial on Training Large-scale Foundation Models on Emerging AI Chips}},
  booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  year = {2023},
  url={https://dl.acm.org/doi/abs/10.1145/3580305.3599573},
  keywords={other},
}
Note that you should replace XXXXXXX.XXXXXXX with the actual DOI of the paper when it becomes available. You should also update the page numbers once they are known.






