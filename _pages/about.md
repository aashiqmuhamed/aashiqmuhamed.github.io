---
layout: about
title: About
permalink: /
subtitle: 
  Ph.D. Student in Computer Science, Carnegie Mellon University
subtitle2:
profile:
  align: right
  image: aashiq.jpg
  image_circular: false # Set to true if you prefer a circular image
  address:
    - amuhamed[AT]andrew[DOT]cmu[DOT]edu
    - Gates Hillman Centers 5418
news: true  # Display a list of news items
latest_posts: false  # Display the newest posts
selected_papers: true # Display selected papers
social: true  # Include social icons at the bottom of the page
---

I am a Ph.D. student in the [CMU Machine Learning Department](https://www.ml.cmu.edu/), advised by Professors [Mona Diab](https://lti.cs.cmu.edu/people/222228496/mona-diab) and [Virginia Smith](https://www.cs.cmu.edu/~smithv/). I also closely collaborate with Professor [Andrew Ilyas](https://andrewilyas.com/).

My research develops the **science and safety infrastructure for autonomous agentic systems**. I work on both the foundational interpretability methods needed to understand how models reason internally, and the applied tools to monitor and govern agents in deployment. I'm particularly interested in:

- **Foundations of Mechanistic Interpretability**: Developing SAEs, circuit analysis, and interpretability methods to understand model internals—including feature consistency, rare concept detection, unlearning, and the geometry of learned representations.
- **Interpretability of Reasoning Models**: Understanding how reasoning capabilities emerge and can be intervened on during training across paradigms (SFT, RLVR, and beyond), and what drives robustness in finetuned reasoning models.
- **Agent Safety Monitoring and Evaluation**: What makes an effective safety monitor? I study chain-of-thought monitoring, mechanistic monitors, and benchmarking their robustness against direct misuse and evasion.
- **Multi-Agent Collusion and Coordination**: Using mechanistic tools to detect and understand collusion, deception, and covert coordination in multi-agent systems.
- **Tamper Resistance and Open-Weight Safety**: Making safety properties robust in open-weight models where adversaries have full access to modify weights.

I am supported by the [Amazon PhD Fellowship](https://www.csd.cs.cmu.edu/news/10-cmu-students-selected-for-amazon-ai-phd-fellowship-program), [Anthropic Fellows Program](https://alignment.anthropic.com/2024/anthropic-fellows-program/), the [Siebel Scholars Foundation](https://www.siebelscholars.com/scholar-profile/3807/), the [Cooperative AI Foundation](https://www.cooperativeai.com/), [Longview Philanthropy](https://www.longview.org/), [CAIS](https://safe.ai/), [SPAR](https://sparai.org/projects/f25/), and [MATS](https://www.matsprogram.org/alumni/aashiq-muhamed).

## background

I bring an interdisciplinary perspective, with degrees spanning engineering, language technologies, and machine learning. I earned my B.Tech in Mechanical Engineering from the Indian Institute of Technology, Roorkee, where I was awarded the President's Gold Medal. I subsequently completed an MS in Mechanical Engineering at Stanford University and an MS in Language Technologies from the [CMU Language Technologies Institute](https://lti.cs.cmu.edu/).

Before beginning my Ph.D., I spent five years in industry as an Applied Scientist at Amazon, working across diverse AI applications including AWS DeepComposer (2019-2021), Amazon Search M5 (2021-2022), and AWS AI (2022-2023). This industry experience deeply informs my research, emphasizing systems that are both theoretically grounded and practically deployable.

I'm always open to collaboration — feel free to reach out.
